# -*- coding: utf-8 -*-
"""Submission MLT Recommendation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WJpawmiaELoy7qgVvxW608DeXuVqe4F9

# **Sistem Rekomendasi**: Rekomendasi Film menggunakan Content Based Filter 

##### Oleh : Muhammad Rionando D
##### Proyek Submission 2 - Machine Learning Terapan Dicoding

# **Pendahuluan**

Pada proyek ini, topik yang dibahas adalah mengenai sistem rekomendasi content based filter menggunakan dataset film yang bersumber dari kaggle

# **1. Mengimpor modul yang dibutuhkan**
"""

# Untuk pengolahan data
import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
import json

# Untuk visualisasi data
import plotly.express as px
import matplotlib.pyplot as plt
import seaborn as sns
from plotly.offline import iplot
import missingno as msno

# Untuk pembuatan sistem rekomendasi 
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

"""# **2. Mempersiapkan Dataset**"""

#install kaggle library 
!pip install kaggle

#upload file kaggle.json
from google.colab import files
files.upload()

#kaggle setup
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
!ls ~/.kaggle

#upload dataset 
!kaggle datasets download -d tmdb/tmdb-movie-metadata

#mengekstrak dataset
!unzip /content/tmdb-movie-metadata.zip

"""# **3. Data Understanding**

## 3.1 Memuat Data pada sebuah Dataframe menggunakan *pandas*
"""

#memuat dataset dan menampilkan data sekilas
df_movies = pd.read_csv("/content/tmdb_5000_movies.csv")
df_credits = pd.read_csv("/content/tmdb_5000_credits.csv")
df_movies.head(10)

df_credits.head(10)

"""## 3.2 Uraian variabel pada dataset"""

#Memuat informasi dataframe
df_movies.info()

#memuat info data frame
df_credits.info()

#melihat kolom
df_movies.columns

#melihat kolom
df_credits.columns

# Menghitung null pada setiap kolom
df_movies.isna().sum()

# Memvisualisasikan data kosong pada setiap kolom
sorted_null = msno.nullity_sort(df_movies, sort='ascending') 
figures = msno.matrix(sorted_null, color=(1, 0.43, 0.43))

#mendiskripsikan dataframe
df_movies.describe()

#mendiskripsikan dataframe
df_credits.describe()

#mengetahui jumlah dataset
print(df_credits.shape)
print(df_movies.shape)

"""# **4. Data Preperation dan EDA**

Mengubah data dari json ke string untuk visualisasi
"""

# mengubah kolom genres dari json ke string
df_movies['genres'] = df_movies['genres'].apply(json.loads)
for index,i in zip(df_movies.index,df_movies['genres']):
    list1 = []
    for j in range(len(i)):
        list1.append((i[j]['name'])) 
    df_movies.loc[index,'genres'] = str(list1)

# mengubah kolom keywoard dari json ke string
df_movies['keywords'] = df_movies['keywords'].apply(json.loads)
for index,i in zip(df_movies.index,df_movies['keywords']):
    list1 = []
    for j in range(len(i)):
        list1.append((i[j]['name']))
    df_movies.loc[index,'keywords'] = str(list1)
    
# mengubah kolom  production_companies dari json ke string
df_movies['production_companies'] = df_movies['production_companies'].apply(json.loads)
for index,i in zip(df_movies.index,df_movies['production_companies']):
    list1 = []
    for j in range(len(i)):
        list1.append((i[j]['name']))
    df_movies.loc[index,'production_companies'] = str(list1)

# mengubah kolom cast dari json ke string
df_credits['cast'] = df_credits['cast'].apply(json.loads)
for index,i in zip(df_credits.index,df_credits['cast']):
    list1 = []
    for j in range(len(i)):
        list1.append((i[j]['name']))
    df_credits.loc[index,'cast'] = str(list1)

# mengubah kolom crew dari json ke string   
df_credits['crew'] = df_credits['crew'].apply(json.loads)
def director(x):
    for i in x:
        if i['job'] == 'Director':
            return i['name']
df_credits['crew'] = df_credits['crew'].apply(director)
df_credits.rename(columns={'crew':'director'},inplace=True)

"""## 4.1 Menggabungkan dataset dan Drop variabel """

# mengganti nama kolom movie_id menjadi id
credits_renamed=df_credits.rename(index=str,columns={'movie_id':'id'})
credits_renamed.head()

# Meenggabungkan dataset
movie=df_movies.merge(credits_renamed,on='id')
movie.head()

# Membuang kolom yang tidak digunakan
movies=movie.drop(columns=['homepage','title_x','title_y','status','production_countries'])
movies.head()

"""## 4.2 EDA

4.2.1 Genres
"""

# Visualisasi Genres
movies['genres'] = movies['genres'].str.strip('[]').str.replace(' ','').str.replace("'",'')
movies['genres'] = movies['genres'].str.split(',')
plt.subplots(figsize=(12,10))
list1 = []
for i in movies['genres']:
    list1.extend(i)
ax = pd.Series(list1).value_counts()[:10].sort_values(ascending=True).plot.barh(width=0.9,color=sns.color_palette('hls',10))
for i, v in enumerate(pd.Series(list1).value_counts()[:10].sort_values(ascending=True).values): 
    ax.text(.8, i, v,fontsize=12,color='white',weight='bold')
plt.title('Top Genres')
plt.show()

"""4.2.2 Cast"""

# Visualisasi cast
movies['cast'] = movies['cast'].str.strip('[]').str.replace(' ','').str.replace("'",'').str.replace('"','')
movies['cast'] = movies['cast'].str.split(',')
plt.subplots(figsize=(12,10))
list1=[]
for i in movies['cast']:
    list1.extend(i)
ax=pd.Series(list1).value_counts()[:15].sort_values(ascending=True).plot.barh(width=0.9,color=sns.color_palette('muted',40))
for i, v in enumerate(pd.Series(list1).value_counts()[:15].sort_values(ascending=True).values): 
    ax.text(.8, i, v,fontsize=10,color='white',weight='bold')
plt.title('Actors with highest appearance')
plt.show()

"""4.2.3 Director"""

#visualisasi director
def xstr(s):
    if s is None:
        return ''
    return str(s)
movies['director'] = movies['director'].apply(xstr)
plt.subplots(figsize=(12,10))
ax = movies[movies['director']!=''].director.value_counts()[:10].sort_values(ascending=True).plot.barh(width=0.9,color=sns.color_palette('muted',40))
for i, v in enumerate(movies[movies['director']!=''].director.value_counts()[:10].sort_values(ascending=True).values): 
    ax.text(.5, i, v,fontsize=12,color='white',weight='bold')
plt.title('Directors with highest movies')
plt.show()

"""## 4.3 Standarisasi"""

# Memilih semua kolom dengan tipe data integer
column_int = df_movies.dtypes[df_movies.dtypes == 'int64'].keys()
column_int

# Memilih semua kolom dengan tipe data float
column_float = df_movies.dtypes[df_movies.dtypes == 'float64'].keys()
column_float

# Menyatukan semua kolom dengan tipe data numerik
column_numeric = list(column_int) + list(column_float)
column_numeric

# Inisiasi minmaxscaler
scaler = MinMaxScaler()

# Melakukan standarisasi data
scaled = scaler.fit_transform(df_movies[column_numeric])

# Mengganti data numerik dengan data yang sudah
# di standarisasi
i=0
for column in column_numeric:
    df_movies[column] = scaled[:,i]
    i += 1

# Melihat hasil standarisasi data
df_movies.head()

"""# **5. Pembuatan Model Content Based Filtering** """

# Inisialisasi TfidfVectorizer
tf = TfidfVectorizer()
 
# Melakukan perhitungan idf pada data cuisine
tf.fit(movies['keywords']) 
 
# Mapping array dari fitur index integer ke fitur nama
tf.get_feature_names()

# Melakukan fit lalu ditransformasikan ke bentuk matrix
tfidf_matrix = tf.fit_transform(movies['keywords']) 
 
# Melihat ukuran matrix tfidf
tfidf_matrix.shape

# Mengubah vektor tf-idf dalam bentuk matriks dengan fungsi todense()
tfidf_matrix.todense()

# Membuat dataframe untuk melihat tf-idf matrix
 
pd.DataFrame(
    tfidf_matrix.todense(), 
    columns=tf.get_feature_names(),
    index=movies.original_title
).sample(22, axis=1).sample(10, axis=0)

# Menghitung cosine similarity pada matrix tf-idf
cosine_sim = cosine_similarity(tfidf_matrix) 
cosine_sim

# Membuat dataframe dari variabel cosine_sim dengan baris dan kolom berupa judul
cosine_sim_df = pd.DataFrame(cosine_sim, index=movies['original_title'], columns=movies['original_title'])
print('Shape:', cosine_sim_df.shape)
 
# Melihat similarity matrix pada setiap judul
cosine_sim_df.sample(5, axis=1).sample(10, axis=0)

def movie_recommendations(original_title, similarity_data=cosine_sim_df, items=movies[['original_title', 'keywords']], k=5):
    """
    Rekomendasi Film berdasarkan kemiripan dataframe
 
    Parameter:
    ---
    original_title : tipe data string (str)
                Judul Film (index kemiripan dataframe)
    similarity_data : tipe data pd.DataFrame (object)
                      Kesamaan dataframe, simetrik, dengan resto sebagai 
                      indeks dan kolom
    items : tipe data pd.DataFrame (object)
            Mengandung kedua nama dan fitur lainnya yang digunakan untuk mendefinisikan kemiripan
    k : tipe data integer (int)
        Banyaknya jumlah rekomendasi yang diberikan
    ---
 
 
    Pada index ini, kita mengambil k dengan nilai similarity terbesar 
    pada index matrix yang diberikan (i).
    """
 
 
    # Mengambil data dengan menggunakan argpartition untuk melakukan partisi secara tidak langsung sepanjang sumbu yang diberikan    
    # Dataframe diubah menjadi numpy
    # Range(start, stop, step)
    index = similarity_data.loc[:,original_title].to_numpy().argpartition(
        range(-1, -k, -1))
    
    # Mengambil data dengan similarity terbesar dari index yang ada
    closest = similarity_data.columns[index[-1:-(k+2):-1]]
    
    # Drop judul agar nama jduul yang dicari tidak muncul dalam daftar rekomendasi
    closest = closest.drop(original_title, errors='ignore')
 
    return pd.DataFrame(closest).merge(items).head(k)

#mengecek judul film
movies[movies.original_title.eq('Saving Private Ryan')]

#mencari rekomendasi film
movie_recommendations('Saving Private Ryan')

"""# **6. Evaluasi Model Content Based Filtering**

Karena pada kasus ini saya hanya menggunakan 1 model dan model yang digunakan adalah content based filtering menggunakan TF-IDF Vectorizer maka metrics evaluasi yang akan saya gunakan adalah precision dan dikarenakan kita tidak bisa menghitung dengan memanggil library scikit learn karena tidak ada data target/label seperti pada supervised learning. maka saya akan menghitung metrics evaluasinya secara manual

precision pada sistem rekomendasi memiliki rumus = junlah rekomendasi yang relevan/total rekomendasi

dari hasil rekomendasi pada model maka ada 5 dari 5 film yang memiliki kata kunci cerita yang similiar dengan Saving Private Ryan maka metrik evaluasinya adalah 5/5= 1

**Precision = 1**

# **Penutupan**

Model sistem rekomendasi film berdasarkan content based filtering telah selesai dibuat dan model ini dapat digunakan untuk merekomendasikan film berdasarkan dataset yang ada. 


### *Referensi*
  - https://www.kaggle.com/tmdb/tmdb-movie-metadata/code?datasetId=138&sortBy=voteCount&searchQuery=col
  - https://www.kaggle.com/heeraldedhia/movie-ratings-and-recommendation-using-knn
  - https://www.kaggle.com/ibtesama/getting-started-with-a-movie-recommendation-system#Collaborative-Filtering
  - https://www.kaggle.com/fabiendaniel/film-recommendation-engine
  - https://ieeexplore.ieee.org/abstract/document/9489125/
"""